{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "#import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_finance import candlestick2_ochl,volume_overlay\n",
    "import talib\n",
    "from math import log, exp\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker as mticker\n",
    "from matplotlib.dates import DateFormatter, WeekdayLocator, DayLocator, MONDAY,YEARLY\n",
    "from matplotlib.dates import MonthLocator,MONTHLY\n",
    "import datetime as dt\n",
    "import pylab\n",
    "import h5py\n",
    "from PIL import Image\n",
    "import os\n",
    "import threading\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "from random import shuffle\n",
    "from numba import vectorize, float64, cuda\n",
    "import imageio\n",
    "import glob\n",
    "import cv2\n",
    "  \n",
    "hdf5_path = 'pic_sum_new.h5' \n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stocknum = {'0051','1102','1216','1227','1314','1319','1434','1451','1476','1477','1504','1536','1560','1590',\n",
    "            '1605','1704','1717','1718','1722','1723','1789','1802','1909','2015','2049','2059','2106','2201',\n",
    "            '2204','2207','2227','2231','2312','2313','2324','2327','2337','2344','2347','2352','2353','2356',\n",
    "            '2360','2371','2376','2377','2379','2385','2439','2448','2449','2451','2478','2492','2498','2542',\n",
    "            '2603','2606','2610','2615','2618','2723','2809','2812','2834','2845','2867','2888','2912','2915',\n",
    "            '3019','3034','3044','3051','3189','3231','3406','3443','3532','3673','3682','3702','3706','4137',\n",
    "            '4915','4943','4958','5264','5522','5871','6005','6116','6176','6239','6269','6285','6409','6414',\n",
    "            '6415','6452','6456','8454','8464','9910','9914','9917','9921','9933','9938','9941','9945'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 將資料傳入 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將圖片改成RGB維度"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for stockid in stocknum:  \n",
    "    df_t = pd.read_hdf(stockid+'_table.h5','stock_data_table')\n",
    "    print(len(df_t))\n",
    "    for num in range(len(df_t)):\n",
    "        pic = Image.open(stockid+'pic/'+str(num)+'_'+stockid+'.png')\n",
    "        pic = pic.convert('RGB')\n",
    "        pic.save(stockid+'pic/'+str(num)+'_'+stockid+'.png')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##############################################    更改圖片名子  1 -->  0001\n",
    "for stockid in stocknum:\n",
    "    df = pd.read_hdf(stockid+'_table_sumchange.h5','stock_data_table')\n",
    "    for num in range(len(df)):\n",
    "        os.rename('D:/專題使用/stock_pic/'+stockid + 'pic/'+ str(num) + '_'+stockid+'.jpg', \n",
    "                  'D:/專題使用/stock_pic/'+stockid + 'pic/'+ str(num).zfill(4) + '_'+stockid+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pic_sum = []\n",
    "table_sum=[]\n",
    "\n",
    "for stockid in stocknum:\n",
    "    df = pd.read_hdf(stockid+'_table_sumchange.h5','stock_data_table')\n",
    "    pic_addr = glob.glob('D:/program/stock_pic/' +stockid + 'pic/'+'*.jpg')\n",
    "    \n",
    "    for item in pic_addr:\n",
    "        item = item.replace('\\\\','/')\n",
    "        #print (item)\n",
    "        pic_sum.append(item)\n",
    "    for table in df.values:\n",
    "        table_sum.append(table)\n",
    "    print(len(pic_sum))\n",
    "    print(len(table_sum))\n",
    "\n",
    "    \n",
    "c = list(zip(pic_sum,table_sum))\n",
    "shuffle(c)\n",
    "addrs, labels = zip(*c)\n",
    "addrs = list(addrs)\n",
    "labels = list(labels)\n",
    "\n",
    "train_addrs = addrs[0:int(0.6*len(addrs))]\n",
    "train_labels = labels[0:int(0.6*len(labels))]\n",
    "\n",
    "\n",
    "val_addrs = addrs[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "val_labels = labels[int(0.6*len(addrs)):int(0.8*len(addrs))]\n",
    "\n",
    "test_addrs = addrs[int(0.8*len(addrs)):]\n",
    "test_labels = labels[int(0.8*len(labels)):]\n",
    "    \n",
    "#train_shape = (len(train_addrs), 380, 383, 3)\n",
    "#val_shape = (len(val_addrs), 380, 383, 3)\n",
    "#test_shape = (len(test_addrs), 380, 383, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_addrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "for i,a in enumerate(train_addrs) :\n",
    "    train_addrs[i] =  a.encode('utf8')\n",
    "for i,a in enumerate(val_addrs) :\n",
    "    val_addrs[i] =  a.encode('utf8')\n",
    "for i,a in enumerate(test_addrs) :\n",
    "    test_addrs[i] =  a.encode('utf8')\n",
    "\n",
    "hdf5_file.create_dataset(\"train_img\", data = train_addrs)\n",
    "hdf5_file.create_dataset(\"val_img\", data=val_addrs)\n",
    "hdf5_file.create_dataset(\"test_img\", data=test_addrs)\n",
    "\n",
    "\n",
    "hdf5_file.create_dataset(\"train_labels\", (len(train_addrs),4), np.int8)\n",
    "hdf5_file[\"train_labels\"][...] = train_labels\n",
    "\n",
    "hdf5_file.create_dataset(\"val_labels\", (len(val_addrs),4), np.int8)\n",
    "hdf5_file[\"val_labels\"][...] = val_labels\n",
    "\n",
    "hdf5_file.create_dataset(\"test_labels\", (len(test_addrs),4), np.int8)\n",
    "hdf5_file[\"test_labels\"][...] = test_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file[\"train_img\"][0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "img = imageio.imread(addr)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(len(train_addrs)):\n",
    " \n",
    "    if i % 10 == 0 and i > 1:\n",
    "        print ('Train data: {}/{}'.format(i, len(train_addrs)))\n",
    "\n",
    "    addr = train_addrs[i]\n",
    "    img = imageio.imread(addr)\n",
    "    hdf5_file[\"train_img\"][i] = img\n",
    "    \n",
    "for i in range(len(val_addrs)):\n",
    "    \n",
    "    if i % 10 == 0 and i > 1:\n",
    "        print ('val data: {}/{}'.format(i, len(val_addrs)))\n",
    "\n",
    "    addr = val_addrs[i]\n",
    "    img = imageio.imread(addr)\n",
    "    hdf5_file[\"val_img\"][i] = img\n",
    "    \n",
    "for i in range(len(test_addrs)):\n",
    "    \n",
    "    if i % 10 == 0 and i > 1:\n",
    "        print ('val data: {}/{}'.format(i, len(test_addrs)))\n",
    "\n",
    "    addr = test_addrs[i]\n",
    "    img = imageio.imread(addr)\n",
    "    hdf5_file[\"test_img\"][i] = img"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "data_num = hdf5_file[\"train_img\"].shape[0]\n",
    "data_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
